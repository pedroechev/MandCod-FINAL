{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb430dc",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Cuando vamos realizar un proyecto de Machine Learning, es importante tener claro ciertos elementos si queremos aportar valor:\n",
    "\n",
    "Primero, definamos el problema: En el caso de este proyecto tenemos la siguiente situación: \"Mandarinas Campesinas\" es un negocio que todas las semanas compra mandarinas en el mercado de Medellín, para luego enviárselas a sus clientes a lo largo y ancho de la ciudad. Este proceso lo repiten todos los años, pero únicamente durante 3 meses de cada año, que es el periodo de cosecha.\n",
    "\n",
    "Últimamente estan pensando en cambiar su modelo de negocio. En vez de ir todas las semanas al mercado de Medellín a negociar el precio al cual compran las mandarinas, van a comprar anticipadamente lo que venden cada semana (que ya saben cuanto es, pues sus clientes son fijos), y así poder obtener dos cosas a cambio: Primero, pueden calcular más facilmente un promedio de sus costos y segundo, al tener toda esta información obtienen un descuento en el total por asumir el riesgo de pagar anticipadamente. Para poder hacer esto, deben saber a que precio se va a vender la mandarina en el mercado el próximo periodo de cosecha y así, proponerle a sus proveedores un negocio que les interese.\n",
    "\n",
    "Ahora, entendamos los datos: Para resolver nuestro problema contamos con los precios mensuales promedio de la Mandarina Oneco de primera categoría que se vende en la Mayorista, recolectados por el SIPSA. Hago referencia a primera categoría porque la mandarina dentro del mercado de la Mayorista es de práctica común que se categorice por tamaños, siendo la de primera la más grande y libre de inperfecciones en la cáscara. Siguiendo a ésta, estan la de segunda y la de tercera, las cuales son respectivamente de menor tamaño a la anterior. El histórico de los precios recorre un periodo desde enero de 2017 hasta julio de 2021, resultando en un total de 55 meses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda4b33",
   "metadata": {},
   "source": [
    "### Modelos a implementar de SERIES DE TIEMPO\n",
    "\n",
    "#### Algoritmos tradicionales\n",
    "\n",
    "- [x] ARIMA \n",
    "\n",
    "\n",
    "#### Algoritmos Machine Learning\n",
    "\n",
    "- [x] Regresor de red neuronal RNN(LSTM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb149ee",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "\n",
    "Al importar nuestros datos, lo primero que debemos hacer para analizar nuestra serie de tiempo es llevar a cabo un análisis visual. Dicho análisis, nos sirve para familiarizarnos con los datos y darnos una idea de que tipo de modelo podríamos implementar, pero para poder sacar alguna conclusión es necesario implementar pruebas más robustas.\n",
    "\n",
    "### Análisis gráfico\n",
    "\n",
    "Al graficar nuestros datos, notamos un comportamiento de la serie aparentemente estacionario, además vemos que en los meses finales de todos los años, la serie llega a precios mínimos lo que puede ser un indicio de cierto patrón de estacionaliad.\n",
    "\n",
    "Lo siguiente en nuestro análisis es que miramos las funciones de autocorrelación y autocorrelación parcial, as cuales sugieren también que dentro de la serie existe un patrón estacional, dado que tienen un \"lag\" alto en el mes 12 para ambas series.\n",
    "\n",
    "### Pruebas de estacionariedad\n",
    "\n",
    "Para confirmar nuestra hipótesis de estaconariedad, realizamos la prueba de *Dieckey-Fuller Aumentado*, la cual nos da un p-valor muy superior a la hipótesis nula de estacionariedad, por lo que rechazamos dicha hipóstesis. Nuestra serie es probablemente No estacionaria. Al obtener este resultado, escogemos diferenciar la serie, y vemos que tiene un comportamiento mucho más estacionario (tener un comportamiento estacionario implica que la media y la varianza son constantes a través del tiempo).\n",
    "\n",
    "### Replanteamos la serie\n",
    "\n",
    "Al realizar la prueba gráfica de ACF y PACF, notamos que únicamente tienen el primer \"lag\" de la serie alto. Teniendo toda esta información a la mano, decidimos aplicar un modelo ARIMA estacionl ó SARIMA(0,1,0)(1,0,1)12, el primer componente hace referencia al orden de la parte no estacional y el segundo componente a la parte estacional. El 12 nos indica que cada 12 periodos (en nuestro caso 12 meses, es decir, un año) se repite la parte estacional de nuestra serie. Seguido a esto, realizamos de nuevo la prueba de *Dieckey-Fuller Aumentado* y esta vez no rechazamos estacionariedad, por lo tanto podemos aplicar nuestro modelo.\n",
    "\n",
    "### Entrenamiento y aplicación del modelo\n",
    "\n",
    "Para entrenar nuestro modelo hacemos una particion de la siguiente manera: De un total de 55 observaciones (dado que tomamos la serie original), 40 obsevaciones van a ser destinadas para el entrenamiento, y el resto de las observaciones para evaluar el comportamiento de nuestro modelo. Al hacer esto, procedemos a entrenar el modelo con los parámetros arriba mencionados.\n",
    "\n",
    "\n",
    "### Resultados\n",
    "\n",
    "Después de esto hacemos un \"forecast\" de nuestro modelo y lo comparamos con los datos de testeo, vemos que tiene un buen comportamiento y obtenemos un rmse de 649.\n",
    "\n",
    "\n",
    "### Extra\n",
    "\n",
    "Además de realizar nuestro modelo, intentamos aplicar las funciones del mismo sistema para que éste mismo haga un análisis de la serie y basado en sus resultados, nos recomiende un modelo a aplicar. En nuestro caso nos recomienda una SARIMA(0,0,2)(0,0,0)0, en otras palabras, un ARMA(0,2). Basados en este modelo realizamos una predicción y lo comparamos con los datos de entrenamiento obteniendo unos resultados un poco por debajo de nuestro modelo, con un rmse de 721. Por lo que mantenemos nuestro primer modelo planteado para pronosticar,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e1f5e",
   "metadata": {},
   "source": [
    "## Regresor de Red Neuronal\n",
    "\n",
    "Ahora, vamos a implementar un modelo de redes neuronales para intentar predecir nuestros datos. Más específicamente LSTM (Long Short Term Memory). Dicho modelo hace parte de un subconjunto de Redes Neuronales usadas dentro del campo de Deep Learning. Éste modelo se comporta bien con secuencias de datos y es uno de los más utilizados para la predicción de series de tiempo, entre otros.\n",
    "\n",
    "La parte de pre-procesamiento de los datos y de entrenamiento las realizamos rápidamente rápidamente gracias a que los datos ya los tenemos listos y organizados. Para esta parte, únicamente vamos a implementar unas cuantas lineas de código. Obtenemos los datos y los graficamos, no es necesario un análisis amlplio dado que ya obtuviemos este análisis en el momento que implementamos nuestro SARIMA. Aún así, añadímos a nuestro catálogo de gráficos a *descomposición* de la serie, que nos da una mirada muy clara con lo que nos estamos enfrentando. Vemos una clara tendencia alcista y un marcado patrón estacional, el cual ya habíamos trabajado en nuestro anterior modelo. También podemos ver el comportamiento de los residuales, que tienen un buen comportamiento aleatorio y no parece que se esten relacionando con alguna variable dependiente exógena.\n",
    "\n",
    "Partimos nuestros datos en la misma proporción que lo hicimos anteriormente: 45 entrenamiento y 10 datos testeo. Luego, convertimos la serie para que ocupe un rango de 0 a 1 (Esto es una práctica común al trabajar con redes LSTM). \n",
    "\n",
    "Posterior a ésto, definimos nuestro generador. Las redes LSTM trabajan con un generador que toma cierto número de inputs (en nuestro caso asignamos 12 meses de input) y predie el siguiente valor. Este proceso lo va iterando y el resultado lo usa para ir auto-ajustandose.\n",
    "\n",
    "El paso siguiente es definir como tal nuestro modelo. Usamos 128 neuronas y una función de activasión \"relu\", además seleccionamos \"adam\" como nuestro optimizador, y \"mse\" como la función de pérdida a la cual debe reducir. Y teniendo en cuenta ésta información, entrenamos nuestro modelo con 50 epochs.\n",
    "\n",
    "Al graficar nuestra función de pérdida después de entrenar el modelo, vemos que va decreciendo con el tiempo llegando desde 0.15 en el primer *epoch* hasta llegar aproximadamente hasta 0.01 en el *epoch* 50.\n",
    "\n",
    "A partir de nuestro modelo, intentamos predecir los 12 siguientes meses y al compararlo con nuestras observaciones reales obtenemos un rmse de 780."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe3515d",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "El negocio de \"Mandarinas Campesinas\" toma en cuenta la información del estudio y después de haber aplicado los 2 modelos se da cuenta que en este caso el modelo que mejor representa el comportamiento de los precios de la mandarina en el mercado de Medellín dentro de la serie es nuestro modelo de SARIMA.\n",
    "\n",
    "Por lo tanto, toma los resultados de este modelo y se da cuenta que para la próxima cosecha (que comienza en julio) de 2022, los precios de las mandarinas van a estar en 2463.9, 70 pesos por debajo de lo que estan hoy (julio 2021). Por lo tanto, toma la decisión de cancelar su adelanto de dinero que tenía pensado y gracias a los datos y al estudio de éstos, puede evitar una posible pérdida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
